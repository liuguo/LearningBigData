Hive优化

-》压缩
（1）开启Map阶段输出压缩
开启输出压缩功能：
set hive.exec.compress.intermediate=true;
开启map输出压缩功能：
set mapreduce.map.output.compress=true;
设置压缩方式：
set mapreduce.map.output.compress.codec=org.apache.hadoop.io.compress.SnappyCodec;

(2)开启reduce输出端压缩
开启最终输出压缩功能
set hive.exec.compress.output=true;
开启最终数据压缩功能
set mapreduce.output.fileoutputformat.compress=true;
设置压缩方式
set mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoo
p.io.compress.SnappyCodec;
设置块压缩
set mapreduce.output.fileoutputformat.compress.type=BLOCK;

-》存储
Hive存储格式：TextFile/SequenceFile/orc/Parquet
orc:Index Data/row Data/stripe Footer
压缩比：
orc > parquet > textFile
查询速度：
orc > textFile
50s > 54s

-》Group by优化
分组：mr程序，map阶段把相同key的数据分发给一个reduce,一个key的量很大。
解决方案：
在map端进行聚合（combiner）
set hive.map.aggr=true;
设置负载均衡
set hive.groupby.skewindata=true;

-》数据倾斜
（1）合理避免数据倾斜
合理设置map数
合并小文件
set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInp
utFormat;
合理设置reduce数
（2）解决数据倾斜
在map端进行聚合（combiner）
set hive.map.aggr=true;
设置负载均衡
set hive.groupby.skewindata=true;
（3）JVM重用
mapred-site.xml
mapreduce.job.jvm.numtasks
10~20